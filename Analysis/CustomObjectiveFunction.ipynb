{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/raid-cita/nhussain/venv-2.7.13/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "xgb.__file__\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "#from sklearn import datasets\n",
    "import numpy as np\n",
    "#from sklearn.model_selection import train_test_split \n",
    "#from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, average_precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all loss functinos assume you are running the default \n",
    "\n",
    "# user define objective function, given prediction, return gradient and second order gradient\n",
    "# this is log likelihood loss\n",
    "\"\"\"def logregobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = 1.0 / (1.0 + np.exp(-preds))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1.0-preds)\n",
    "    print grad#, hess\n",
    "    return grad, hess\"\"\"\n",
    "\n",
    "\n",
    "def logregobj(y_true, y_pred):\n",
    "    #labels = dtrain.get_label()\n",
    "    #go a logistic transform on it\n",
    "    preds = 1.0 / (1.0 + np.exp(-y_pred))\n",
    "    grad = preds - y_true\n",
    "    hess = preds * (1.0-preds)\n",
    "    #print grad#, hess\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "#square loss function\n",
    "def sq_loss(y_true, y_pred):\n",
    "    #undo the automatic logistic transformation\n",
    "    #preds = -np.log(1./preds - 1)\n",
    "    #apply square loss to the predictions\n",
    "    preds = (1- y_true*y_pred)**2 # the objective function\n",
    "    grad = 2*-y_true*(1- y_true*y_pred)\n",
    "    hess = 2*y_true**2 #? is this right?\n",
    "\n",
    "    return grad, hess\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def default(y_true, y_pred):\n",
    "    #try mean sq errror\n",
    "    preds = (1./y_true.shape[0])*(y_true - y_pred)**2\n",
    "    grad = (1./y_true.shape[0])* -2*(y_true - y_pred)\n",
    "    hess = np.zeros_like(grad)\n",
    "    hess.fill(2 * (1./y_true.shape[0]))\n",
    "    #hess = 2\n",
    "    #print grad#, hess\n",
    "    return grad, hess\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "\n",
    "#hinge loss function not possible due it not being differentialble at y*f(x) =1\n",
    "#needs to use subgradient descent models\n",
    "\n",
    "def quad_loss(y_true, y_pred):\n",
    "    #signature ytrue, _ypred\n",
    "    #labels = dtrain.get_label()\n",
    "    #undo the automatic logistic transformation\n",
    "    #preds = -np.log(1./preds - 1)\n",
    "    preds = (y_true - y_pred)**2\n",
    "    grad = -2*(y_true - y_pred)\n",
    "    hess = np.zeros_like(grad)\n",
    "    hess.fill(2)\n",
    "    #hess = 2\n",
    "    #print grad#, hess\n",
    "    return grad, hess\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User defined evaluation function, returns a pair metric_name, and result\n",
    "NOTE: when you do customized loss function, the default prediction value is margin.\n",
    "This may make builtin evaluation metric not function properly. For example, we are doing logistic loss, the prediction is score before logistic transformation. The builtin evaluation error assumes input is after logistic transformation.\n",
    "Take this in mind when you use the customization, and maybe you need write customized evaluation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stable</th>\n",
       "      <th>instability_time</th>\n",
       "      <th>RHill12</th>\n",
       "      <th>RHill23</th>\n",
       "      <th>beta12</th>\n",
       "      <th>beta23</th>\n",
       "      <th>m1</th>\n",
       "      <th>a1</th>\n",
       "      <th>P1</th>\n",
       "      <th>e1</th>\n",
       "      <th>...</th>\n",
       "      <th>Omega2</th>\n",
       "      <th>f2</th>\n",
       "      <th>m3</th>\n",
       "      <th>a3</th>\n",
       "      <th>P3</th>\n",
       "      <th>e3</th>\n",
       "      <th>pomega3</th>\n",
       "      <th>inc3</th>\n",
       "      <th>Omega3</th>\n",
       "      <th>f3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.235644e+07</td>\n",
       "      <td>0.026033</td>\n",
       "      <td>0.023222</td>\n",
       "      <td>8.508586</td>\n",
       "      <td>15.826967</td>\n",
       "      <td>3.414016e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>...</td>\n",
       "      <td>1.573978</td>\n",
       "      <td>-0.567081</td>\n",
       "      <td>1.826900e-06</td>\n",
       "      <td>1.589043</td>\n",
       "      <td>2.003050</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>-0.108162</td>\n",
       "      <td>0.065498</td>\n",
       "      <td>-1.192440</td>\n",
       "      <td>-0.614709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.348749e+05</td>\n",
       "      <td>0.022704</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>8.397002</td>\n",
       "      <td>15.367618</td>\n",
       "      <td>2.529838e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.749616</td>\n",
       "      <td>1.437355</td>\n",
       "      <td>1.955797e-05</td>\n",
       "      <td>1.671403</td>\n",
       "      <td>2.160777</td>\n",
       "      <td>0.072450</td>\n",
       "      <td>-0.343874</td>\n",
       "      <td>0.046939</td>\n",
       "      <td>-0.619350</td>\n",
       "      <td>0.192203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.276381e+04</td>\n",
       "      <td>0.036304</td>\n",
       "      <td>0.032149</td>\n",
       "      <td>3.461288</td>\n",
       "      <td>25.229467</td>\n",
       "      <td>7.380789e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.051912</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032550</td>\n",
       "      <td>-0.317958</td>\n",
       "      <td>1.477931e-07</td>\n",
       "      <td>1.936762</td>\n",
       "      <td>2.695151</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>3.419165</td>\n",
       "      <td>0.014535</td>\n",
       "      <td>2.795101</td>\n",
       "      <td>1.685406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>0.011704</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>18.513681</td>\n",
       "      <td>19.145889</td>\n",
       "      <td>5.174804e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946351</td>\n",
       "      <td>-2.294238</td>\n",
       "      <td>1.287851e-06</td>\n",
       "      <td>1.503164</td>\n",
       "      <td>1.842927</td>\n",
       "      <td>0.057380</td>\n",
       "      <td>-0.829096</td>\n",
       "      <td>0.098014</td>\n",
       "      <td>-2.995941</td>\n",
       "      <td>-1.625763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8.791888e+01</td>\n",
       "      <td>0.006199</td>\n",
       "      <td>0.008634</td>\n",
       "      <td>5.494196</td>\n",
       "      <td>2.928938</td>\n",
       "      <td>5.106746e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.455684</td>\n",
       "      <td>-1.074927</td>\n",
       "      <td>1.542321e-06</td>\n",
       "      <td>1.059346</td>\n",
       "      <td>1.090326</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>-1.214839</td>\n",
       "      <td>0.011840</td>\n",
       "      <td>-1.253823</td>\n",
       "      <td>1.215392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>0.020053</td>\n",
       "      <td>0.037523</td>\n",
       "      <td>28.331058</td>\n",
       "      <td>22.457059</td>\n",
       "      <td>7.391032e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.275931</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.677006</td>\n",
       "      <td>0.082399</td>\n",
       "      <td>2.429857e-05</td>\n",
       "      <td>2.410783</td>\n",
       "      <td>3.743059</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>1.361753</td>\n",
       "      <td>0.063358</td>\n",
       "      <td>1.756039</td>\n",
       "      <td>-0.525618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1.493010e+02</td>\n",
       "      <td>0.026081</td>\n",
       "      <td>0.026966</td>\n",
       "      <td>8.587023</td>\n",
       "      <td>1.013100</td>\n",
       "      <td>2.398945e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.030108</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.997728</td>\n",
       "      <td>1.212560</td>\n",
       "      <td>2.851700e-06</td>\n",
       "      <td>1.251277</td>\n",
       "      <td>1.399645</td>\n",
       "      <td>0.027982</td>\n",
       "      <td>-2.804719</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>-1.224442</td>\n",
       "      <td>1.668318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>5.211392e+02</td>\n",
       "      <td>0.007409</td>\n",
       "      <td>0.014891</td>\n",
       "      <td>3.100652</td>\n",
       "      <td>16.540578</td>\n",
       "      <td>9.364795e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>...</td>\n",
       "      <td>1.402652</td>\n",
       "      <td>-2.340906</td>\n",
       "      <td>8.970227e-06</td>\n",
       "      <td>1.269280</td>\n",
       "      <td>1.429994</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>-0.328554</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>-2.657141</td>\n",
       "      <td>-3.790768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>8.313842e-01</td>\n",
       "      <td>0.029568</td>\n",
       "      <td>0.048262</td>\n",
       "      <td>21.439691</td>\n",
       "      <td>3.470373</td>\n",
       "      <td>4.787597e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>...</td>\n",
       "      <td>1.471415</td>\n",
       "      <td>0.125609</td>\n",
       "      <td>2.393276e-07</td>\n",
       "      <td>1.801408</td>\n",
       "      <td>2.417694</td>\n",
       "      <td>0.014567</td>\n",
       "      <td>1.676149</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>2.561428</td>\n",
       "      <td>-0.615348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1.057243e+02</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.010349</td>\n",
       "      <td>26.130294</td>\n",
       "      <td>1.186617</td>\n",
       "      <td>2.449188e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987448</td>\n",
       "      <td>1.495475</td>\n",
       "      <td>2.603864e-07</td>\n",
       "      <td>1.294191</td>\n",
       "      <td>1.472302</td>\n",
       "      <td>0.014135</td>\n",
       "      <td>-5.586081</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>-3.102203</td>\n",
       "      <td>-0.478592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stable  instability_time   RHill12   RHill23     beta12     beta23  \\\n",
       "0       0      1.235644e+07  0.026033  0.023222   8.508586  15.826967   \n",
       "1       0      1.348749e+05  0.022704  0.031284   8.397002  15.367618   \n",
       "2       0      1.276381e+04  0.036304  0.032149   3.461288  25.229467   \n",
       "3       1      1.000000e+09  0.011704  0.014963  18.513681  19.145889   \n",
       "4       0      8.791888e+01  0.006199  0.008634   5.494196   2.928938   \n",
       "5       1      1.000000e+09  0.020053  0.037523  28.331058  22.457059   \n",
       "6       0      1.493010e+02  0.026081  0.026966   8.587023   1.013100   \n",
       "7       0      5.211392e+02  0.007409  0.014891   3.100652  16.540578   \n",
       "8       0      8.313842e-01  0.029568  0.048262  21.439691   3.470373   \n",
       "9       0      1.057243e+02  0.010789  0.010349  26.130294   1.186617   \n",
       "\n",
       "             m1   a1        P1        e1    ...       Omega2        f2  \\\n",
       "0  3.414016e-05  1.0  0.999983  0.005031    ...     1.573978 -0.567081   \n",
       "1  2.529838e-07  1.0  1.000000  0.010350    ...    -1.749616  1.437355   \n",
       "2  7.380789e-05  1.0  0.999963  0.051912    ...    -0.032550 -0.317958   \n",
       "3  5.174804e-07  1.0  1.000000  0.000152    ...     0.946351 -2.294238   \n",
       "4  5.106746e-07  1.0  1.000000  0.001457    ...    -0.455684 -1.074927   \n",
       "5  7.391032e-06  1.0  0.999996  0.275931    ...    -2.677006  0.082399   \n",
       "6  2.398945e-05  1.0  0.999988  0.030108    ...    -1.997728  1.212560   \n",
       "7  9.364795e-07  1.0  1.000000  0.002121    ...     1.402652 -2.340906   \n",
       "8  4.787597e-07  1.0  1.000000  0.001424    ...     1.471415  0.125609   \n",
       "9  2.449188e-06  1.0  0.999999  0.002222    ...     0.987448  1.495475   \n",
       "\n",
       "             m3        a3        P3        e3   pomega3      inc3    Omega3  \\\n",
       "0  1.826900e-06  1.589043  2.003050  0.002515 -0.108162  0.065498 -1.192440   \n",
       "1  1.955797e-05  1.671403  2.160777  0.072450 -0.343874  0.046939 -0.619350   \n",
       "2  1.477931e-07  1.936762  2.695151  0.003395  3.419165  0.014535  2.795101   \n",
       "3  1.287851e-06  1.503164  1.842927  0.057380 -0.829096  0.098014 -2.995941   \n",
       "4  1.542321e-06  1.059346  1.090326  0.010325 -1.214839  0.011840 -1.253823   \n",
       "5  2.429857e-05  2.410783  3.743059  0.005295  1.361753  0.063358  1.756039   \n",
       "6  2.851700e-06  1.251277  1.399645  0.027982 -2.804719  0.003511 -1.224442   \n",
       "7  8.970227e-06  1.269280  1.429994  0.001304 -0.328554  0.001379 -2.657141   \n",
       "8  2.393276e-07  1.801408  2.417694  0.014567  1.676149  0.008059  2.561428   \n",
       "9  2.603864e-07  1.294191  1.472302  0.014135 -5.586081  0.001207 -3.102203   \n",
       "\n",
       "         f3  \n",
       "0 -0.614709  \n",
       "1  0.192203  \n",
       "2  1.685406  \n",
       "3 -1.625763  \n",
       "4  1.215392  \n",
       "5 -0.525618  \n",
       "6  1.668318  \n",
       "7 -3.790768  \n",
       "8 -0.615348  \n",
       "9 -0.478592  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../csvs/initial_orbital_elements.csv\", index_col=0)\n",
    "del df[\"runstring\"]\n",
    "del df[\"Rel_Eerr\"]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "regY = df[\"instability_time\"]\n",
    "del df[\"instability_time\"]\n",
    "Y = df[\"Stable\"]\n",
    "X = df.copy()\n",
    "#X = df.drop(\"Stable\")\n",
    "del X[\"Stable\"]\n",
    "X.head()\n",
    "\n",
    "cut = int(X.shape[0] * 0.4)\n",
    "trainX = X.loc[:cut-1]\n",
    "trainY = Y.loc[:cut-1]\n",
    "trainrY = regY.loc[:cut-1]\n",
    "testX = X.loc[cut:]\n",
    "testY = Y.loc[cut:]\n",
    "testrY = regY.loc[cut:]\n",
    "\n",
    "#print testX.shape, trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = xgb.XGBClassifier(n_estimators=100, max_depth=10, min_child_weight=3, \n",
    "                               objective=quad_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=3, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bst = xgb.train(param, dtrain, 3, watchlist, sq_loss )\n",
    "classifier.fit(trainX, trainY, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892239820619\n"
     ]
    }
   ],
   "source": [
    "#This is with quadratic loss\n",
    "predY= classifier.predict(testX)\n",
    "score = average_precision_score(testY, predY)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.698733333333\n"
     ]
    }
   ],
   "source": [
    "#square loss\n",
    "classifier2 = xgb.XGBClassifier(n_estimators=100, max_depth=10, min_child_weight=3, \n",
    "                               objective=sq_loss)\n",
    "classifier2.fit(trainX, trainY, verbose = True)\n",
    "preds = classifier2.predict(testX)\n",
    "score = average_precision_score(testY, preds)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.886591744147\n"
     ]
    }
   ],
   "source": [
    "#\"reg:logistic\" --logistic regression\n",
    "log_reg= xgb.XGBClassifier(n_estimators=100, max_depth=10, min_child_weight=3, objective=logregobj)\n",
    "log_reg.fit(trainX, trainY)\n",
    "preds = log_reg.predict(testX)\n",
    "score = average_precision_score(testY, preds)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.913784017919\n"
     ]
    }
   ],
   "source": [
    "#builtin objective function\n",
    "original= xgb.XGBClassifier(n_estimators=100, max_depth=10, min_child_weight=3)\n",
    "original.fit(trainX, trainY)\n",
    "preds = original.predict(testX)\n",
    "score = average_precision_score(testY, preds)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "(1 - norm.cdf(0))*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Account for sigma\n",
    "def mse(y_true, y_pred):\n",
    "    #print y_pred[1], y_true[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    preds = (1/0.4**2)*(y_true - y_pred)**2\n",
    "    grad = (1/0.4**2)* -2*(y_true - y_pred)\n",
    "    hess = np.zeros_like(grad)\n",
    "    hess.fill((1/0.4**2)*2)\n",
    "    #hess = 2\n",
    "    #print grad#, hess\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.249999999999999"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1/0.4**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.890262030216\n"
     ]
    }
   ],
   "source": [
    "#the defult should be reg:linear\n",
    "#builtin objective function\n",
    "\n",
    "\n",
    "original= xgb.XGBClassifier(n_estimators=100, max_depth=10, min_child_weight=3, objective=mse)\n",
    "original.fit(trainX, trainY)\n",
    "preds = original.predict(testX)\n",
    "score = average_precision_score(testY, preds)\n",
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to predict on a fixed sigma? \n",
    "Use it to provide upper and lower bounds on stability probability?\n",
    "The easiest way to do this is to change the labels based on its stability time shifted up and down from its mean by the fixed sigma value. \n",
    "This is not possible, as only orbits with t >=1e9 are deemed stable, with the rest being unstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7feb27020390>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEDCAYAAADdpATdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb27b52cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "x = np.arange(preds.shape[0])\n",
    "cut = 100\n",
    "plt.scatter(x[:cut],preds[:cut])\n",
    "plt.scatter(x[:cut],testrY[:cut])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stable</th>\n",
       "      <th>RHill12</th>\n",
       "      <th>RHill23</th>\n",
       "      <th>beta12</th>\n",
       "      <th>beta23</th>\n",
       "      <th>m1</th>\n",
       "      <th>a1</th>\n",
       "      <th>P1</th>\n",
       "      <th>e1</th>\n",
       "      <th>pomega1</th>\n",
       "      <th>...</th>\n",
       "      <th>Omega2</th>\n",
       "      <th>f2</th>\n",
       "      <th>m3</th>\n",
       "      <th>a3</th>\n",
       "      <th>P3</th>\n",
       "      <th>e3</th>\n",
       "      <th>pomega3</th>\n",
       "      <th>inc3</th>\n",
       "      <th>Omega3</th>\n",
       "      <th>f3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.026033</td>\n",
       "      <td>0.023222</td>\n",
       "      <td>8.508586</td>\n",
       "      <td>15.826967</td>\n",
       "      <td>3.414016e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>3.171041</td>\n",
       "      <td>...</td>\n",
       "      <td>1.573978</td>\n",
       "      <td>-0.567081</td>\n",
       "      <td>1.826900e-06</td>\n",
       "      <td>1.589043</td>\n",
       "      <td>2.003050</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>-0.108162</td>\n",
       "      <td>0.065498</td>\n",
       "      <td>-1.192440</td>\n",
       "      <td>-0.614709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.022704</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>8.397002</td>\n",
       "      <td>15.367618</td>\n",
       "      <td>2.529838e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>-3.564030</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.749616</td>\n",
       "      <td>1.437355</td>\n",
       "      <td>1.955797e-05</td>\n",
       "      <td>1.671403</td>\n",
       "      <td>2.160777</td>\n",
       "      <td>0.072450</td>\n",
       "      <td>-0.343874</td>\n",
       "      <td>0.046939</td>\n",
       "      <td>-0.619350</td>\n",
       "      <td>0.192203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.036304</td>\n",
       "      <td>0.032149</td>\n",
       "      <td>3.461288</td>\n",
       "      <td>25.229467</td>\n",
       "      <td>7.380789e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.051912</td>\n",
       "      <td>0.995149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032550</td>\n",
       "      <td>-0.317958</td>\n",
       "      <td>1.477931e-07</td>\n",
       "      <td>1.936762</td>\n",
       "      <td>2.695151</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>3.419165</td>\n",
       "      <td>0.014535</td>\n",
       "      <td>2.795101</td>\n",
       "      <td>1.685406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.011704</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>18.513681</td>\n",
       "      <td>19.145889</td>\n",
       "      <td>5.174804e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>-3.328433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946351</td>\n",
       "      <td>-2.294238</td>\n",
       "      <td>1.287851e-06</td>\n",
       "      <td>1.503164</td>\n",
       "      <td>1.842927</td>\n",
       "      <td>0.057380</td>\n",
       "      <td>-0.829096</td>\n",
       "      <td>0.098014</td>\n",
       "      <td>-2.995941</td>\n",
       "      <td>-1.625763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006199</td>\n",
       "      <td>0.008634</td>\n",
       "      <td>5.494196</td>\n",
       "      <td>2.928938</td>\n",
       "      <td>5.106746e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>1.738448</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.455684</td>\n",
       "      <td>-1.074927</td>\n",
       "      <td>1.542321e-06</td>\n",
       "      <td>1.059346</td>\n",
       "      <td>1.090326</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>-1.214839</td>\n",
       "      <td>0.011840</td>\n",
       "      <td>-1.253823</td>\n",
       "      <td>1.215392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stable   RHill12   RHill23     beta12     beta23            m1   a1  \\\n",
       "0       0  0.026033  0.023222   8.508586  15.826967  3.414016e-05  1.0   \n",
       "1       0  0.022704  0.031284   8.397002  15.367618  2.529838e-07  1.0   \n",
       "2       0  0.036304  0.032149   3.461288  25.229467  7.380789e-05  1.0   \n",
       "3       1  0.011704  0.014963  18.513681  19.145889  5.174804e-07  1.0   \n",
       "4       0  0.006199  0.008634   5.494196   2.928938  5.106746e-07  1.0   \n",
       "\n",
       "         P1        e1   pomega1    ...       Omega2        f2            m3  \\\n",
       "0  0.999983  0.005031  3.171041    ...     1.573978 -0.567081  1.826900e-06   \n",
       "1  1.000000  0.010350 -3.564030    ...    -1.749616  1.437355  1.955797e-05   \n",
       "2  0.999963  0.051912  0.995149    ...    -0.032550 -0.317958  1.477931e-07   \n",
       "3  1.000000  0.000152 -3.328433    ...     0.946351 -2.294238  1.287851e-06   \n",
       "4  1.000000  0.001457  1.738448    ...    -0.455684 -1.074927  1.542321e-06   \n",
       "\n",
       "         a3        P3        e3   pomega3      inc3    Omega3        f3  \n",
       "0  1.589043  2.003050  0.002515 -0.108162  0.065498 -1.192440 -0.614709  \n",
       "1  1.671403  2.160777  0.072450 -0.343874  0.046939 -0.619350  0.192203  \n",
       "2  1.936762  2.695151  0.003395  3.419165  0.014535  2.795101  1.685406  \n",
       "3  1.503164  1.842927  0.057380 -0.829096  0.098014 -2.995941 -1.625763  \n",
       "4  1.059346  1.090326  0.010325 -1.214839  0.011840 -1.253823  1.215392  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
